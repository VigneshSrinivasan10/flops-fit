# Requirements Archive: v1.0 MVP

**Archived:** 2026-02-18
**Status:** SHIPPED

For current requirements, see `.planning/REQUIREMENTS.md`.

---

# Requirements: flops-fit

**Defined:** 2026-02-16
**Core Value:** Given a compute budget, tell the user exactly how big their model should be and how much data to train on â€” for their specific architecture and dataset.

## v1 Requirements

### Library API

- [ ] **API-01**: User can call `flops_fit.find_optimal()` with a model class, dataset, loss function, and compute budgets to get scaling law predictions
- [ ] **API-02**: User passes a model class + size parameter name + model kwargs; library creates models at different sizes by varying the size parameter
- [ ] **API-03**: User passes a dataset object (PyTorch Dataset or DataLoader); library handles batching and iteration
- [ ] **API-04**: User passes a loss callable; library uses it during training
- [ ] **API-05**: Result object has `.chinchilla_table()` returning optimal N, D, and loss for each compute budget
- [ ] **API-06**: Result object has `.plot()` producing scaling law and IsoFLOP visualizations
- [ ] **API-07**: Result object has `.predict(compute_budget)` returning optimal N, D, and expected loss for a specific budget

### Training

- [ ] **TRAIN-01**: Library trains models on available GPU with automatic device placement
- [ ] **TRAIN-02**: Library supports multi-GPU data parallelism via Accelerate
- [ ] **TRAIN-03**: Sweep can be resumed if interrupted (completed experiments not re-run)

### Analysis

- [ ] **ANLZ-01**: Library fits power laws (N_opt, D_opt, L_opt vs compute) with R-squared values
- [ ] **ANLZ-02**: Analyzer automatically detects and excludes outlier experiments before fitting
- [ ] **ANLZ-03**: Chinchilla-style table output with optimal N, D, loss for range of budgets

### Examples

- [ ] **EX-01**: GPT + TinyStories example showing text-based scaling law experiments
- [ ] **EX-02**: ViT + CIFAR example showing image-based scaling law experiments
- [ ] **EX-03**: CLI wrapper example showing how to use the library from command line

### Sweep Planning

- [ ] **SWEEP-01**: IsoFLOP sweep planning generates experiment grid across compute budgets
- [ ] **SWEEP-02**: User can estimate total compute cost before running a sweep

## v2 Requirements

- **ANLZ-04**: Confidence intervals on fitted scaling law exponents
- **ANLZ-05**: Parametric loss surface fitting (Chinchilla Approach 3)
- **ANLZ-06**: Multiple fitting approaches (IsoFLOP vs Kaplan-style)
- **TRAIN-04**: Full per-experiment checkpointing for interrupted individual runs
- **API-08**: Config file as alternative input (YAML describing the experiment)

## Out of Scope

| Feature | Reason |
|---------|--------|
| Non-text/non-image modalities | Defer to future; other modalities work if user handles data |
| Config-driven model architecture | Users write Python classes |
| Distributed multi-node training | Single-node multi-GPU is sufficient for v1 |
| Web dashboard | Researchers use W&B/TensorBoard |
| Cloud job submission | Users have their own infrastructure |
| Auto HP tuning across scales | u-mup solves this |
| Hydra as primary interface | Library API is primary; Hydra stays in examples only |

## Traceability

| Requirement | Phase | Status |
|-------------|-------|--------|
| API-01 | Phase 1 | Pending |
| API-02 | Phase 1 | Pending |
| API-03 | Phase 2 | Pending |
| API-04 | Phase 2 | Pending |
| API-05 | Phase 6 | Pending |
| API-06 | Phase 6 | Pending |
| API-07 | Phase 6 | Pending |
| TRAIN-01 | Phase 4 | Pending |
| TRAIN-02 | Phase 9 | Pending |
| TRAIN-03 | Phase 4 | Pending |
| ANLZ-01 | Phase 5 | Pending |
| ANLZ-02 | Phase 5 | Pending |
| ANLZ-03 | Phase 5 | Pending |
| EX-01 | Phase 7 | Pending |
| EX-02 | Phase 8 | Pending |
| EX-03 | Phase 7 | Pending |
| SWEEP-01 | Phase 3 | Pending |
| SWEEP-02 | Phase 3 | Pending |

**Coverage:**
- v1 requirements: 18 total
- Mapped to phases: 18
- Unmapped: 0

---
*Requirements defined: 2026-02-16*
*Last updated: 2026-02-16 -- phase mappings added after roadmap creation (library-first pivot)*
