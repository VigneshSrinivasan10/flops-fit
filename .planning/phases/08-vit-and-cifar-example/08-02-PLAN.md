---
phase: 08-vit-and-cifar-example
plan: 02
type: execute
wave: 2
depends_on: ["08-01"]
files_modified:
  - src/flops_fit/examples/example_vit_cifar.py
  - tests/test_examples.py
autonomous: true

must_haves:
  truths:
    - "example_vit_cifar.py runs to completion in mock mode without GPU or network (python -m flops_fit.examples.example_vit_cifar)"
    - "example_vit_cifar.py accepts --real flag to use actual CIFAR-10 data and local training"
    - "test_examples.py ViT tests cover: contract (num_params), loss function shape, CIFAR lazy-load, and example smoke test"
    - "Total test count increases from 188 to 200+ (new ViT tests added)"
    - "No existing GPT tests regress"
  artifacts:
    - path: "src/flops_fit/examples/example_vit_cifar.py"
      provides: "Runnable ViT + CIFAR scaling law demo with mock/real modes"
      contains: "def make_vit_factory"
    - path: "tests/test_examples.py"
      provides: "ViT contract and example smoke tests alongside existing GPT tests"
      contains: "class TestViTContract"
  key_links:
    - from: "src/flops_fit/examples/example_vit_cifar.py"
      to: "flops_fit.find_optimal()"
      via: "import flops_fit; flops_fit.find_optimal(model_cls=factory, model_size_param='embed_dim', ...)"
      pattern: "flops_fit.find_optimal"
    - from: "src/flops_fit/examples/example_vit_cifar.py"
      to: "src/flops_fit/examples/vit.py"
      via: "from flops_fit.examples import VisionTransformer, vit_loss_fn"
      pattern: "from flops_fit.examples import VisionTransformer"
---

<objective>
Create the ViT + CIFAR example script and tests for Phase 8.

Purpose: Provide a runnable end-to-end demo that proves flops_fit.find_optimal() is architecture-agnostic — same API call, different modality (images vs text), different loss pattern (direct logits vs tuple).
Output: example_vit_cifar.py (parallel to example_programmatic.py), new ViT test classes in test_examples.py.
</objective>

<execution_context>
@/home/viggie/.claude/get-shit-done/workflows/execute-plan.md
@/home/viggie/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/STATE.md
@.planning/phases/07-gpt-and-tinystories-example/07-02-SUMMARY.md
@.planning/phases/08-vit-and-cifar-example/08-01-SUMMARY.md

# Templates to mirror exactly
@src/flops_fit/examples/example_programmatic.py
@tests/test_examples.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create example_vit_cifar.py — runnable demo script</name>
  <files>src/flops_fit/examples/example_vit_cifar.py</files>
  <action>
    Create src/flops_fit/examples/example_vit_cifar.py mirroring the structure of example_programmatic.py:

    Module docstring: explain ViT + CIFAR scaling law demo, mock vs real modes, how embed_dim is the size parameter.

    **make_vit_factory(num_layers=6, num_heads=8, patch_size=4) function:**
    - Returns closure: create_vit(embed_dim: int) -> VisionTransformer
    - VisionTransformer(image_size=32, patch_size=patch_size, num_classes=10, embed_dim=embed_dim, num_layers=num_layers, num_heads=num_heads)
    - Note in docstring: embed_dim must be divisible by num_heads; ensure sweep sizes are multiples of 8

    **_make_synthetic_cifar_dataset(size=128) function:**
    - Creates a TensorDataset of synthetic image-like data for mock mode
    - images = torch.randn(size, 3, 32, 32)        # float32 already normalized
    - labels = torch.randint(0, 10, (size,))        # integer class labels [0..9]
    - return TensorDataset(images, labels)
    - Note: labels are Long dtype — use labels.long()

    **run(use_real_data=False, output_dir="outputs/vit_cifar") function:**
    - Print header: "flops_fit: ViT + CIFAR-10 Scaling Law Example"
    - model_cls = make_vit_factory(num_layers=4, num_heads=8, patch_size=4)
    - If use_real_data: load CIFAR10Dataset(train=True); trainer_mode = "local"
    - Else: _make_synthetic_cifar_dataset(); trainer_mode = "mock"
    - compute_budgets = [1e12, 3e12, 1e13, 3e13, 1e14]  (same as GPT example for comparable demo)
    - result = flops_fit.find_optimal(
          model_cls=model_cls,
          model_size_param="embed_dim",    # KEY: embed_dim is the size parameter (not d_model)
          dataset=dataset,
          loss_fn=vit_loss_fn,             # KEY: takes (logits, labels) directly — no tuple unpacking
          compute_budgets=compute_budgets,
          train=True,
          mode=trainer_mode,
          output_dir=output_dir,
      )
    - Print result.chinchilla_table()
    - result.plot(show=False)
    - return result

    **main() with argparse:**
    - --real flag (action="store_true"): use CIFAR-10 download + local training
    - --output-dir (default="outputs/vit_cifar")

    **Imports:** argparse, torch, torch.nn.functional as F (not actually used since vit_loss_fn is in vit.py), flops_fit, from flops_fit.examples import VisionTransformer, vit_loss_fn, CIFAR10Dataset, from torch.utils.data import TensorDataset

    if __name__ == "__main__": main()
  </action>
  <verify>
    # Smoke test: import + make_vit_factory works
    python -c "
    from flops_fit.examples.example_vit_cifar import make_vit_factory, _make_synthetic_cifar_dataset, vit_loss_fn
    import torch

    # Factory creates ViT with num_params()
    factory = make_vit_factory(num_layers=2, num_heads=8)
    model = factory(embed_dim=64)
    assert model.num_params() > 0

    # Synthetic dataset shape
    ds = _make_synthetic_cifar_dataset(size=16)
    img, label = ds[0]
    assert img.shape == (3, 32, 32)
    assert isinstance(label.item(), int)

    # Loss fn (direct logits, not tuple)
    logits = model(img.unsqueeze(0))
    loss = vit_loss_fn(logits, torch.tensor([label.item()]))
    assert loss.ndim == 0
    print('example_vit_cifar.py OK')
    "
  </verify>
  <done>example_vit_cifar.py importable; make_vit_factory creates VisionTransformer with num_params(); _make_synthetic_cifar_dataset returns (3,32,32) image tensors with integer labels; script runnable via `python -m flops_fit.examples.example_vit_cifar` in mock mode without GPU or network.</done>
</task>

<task type="auto">
  <name>Task 2: Add ViT test classes to tests/test_examples.py</name>
  <files>tests/test_examples.py</files>
  <action>
    Append four new test classes to tests/test_examples.py (after the existing GPT/TinyStories tests):

    **TestViTContract:**
    - test_num_params_method_exists: VisionTransformer(embed_dim=64, num_layers=2, num_heads=8).num_params() returns positive int
    - test_num_params_increases_with_embed_dim: embed_dim=128 produces more params than embed_dim=64
    - test_forward_returns_correct_shape: forward(torch.randn(2, 3, 32, 32)) returns shape (2, 10)
    - test_forward_returns_tensor_not_tuple: type(output) is torch.Tensor (not tuple — contrast with GPT)

    **TestViTLossFunction:**
    - test_vit_loss_fn_accepts_direct_logits: vit_loss_fn(torch.randn(2, 10), torch.randint(0,10,(2,))) returns scalar
    - test_vit_loss_fn_returns_scalar: loss.ndim == 0
    - test_vit_loss_fn_positive: loss.item() > 0

    **TestCIFAR10DatasetLazyLoad:**
    - test_import_is_instant: import CIFAR10Dataset succeeds without network call
    - test_instantiation_does_not_load_data: CIFAR10Dataset()._dataset is None after __init__
    - test_attributes_stored: train=False, data_dir="/tmp/test" stored correctly

    **TestViTExampleScript:**
    - test_make_vit_factory_creates_vit_with_num_params: make_vit_factory(num_layers=2, num_heads=8) returns callable producing VisionTransformer with num_params() > 0
    - test_make_synthetic_cifar_dataset_shape: _make_synthetic_cifar_dataset(size=8) returns dataset of length 8, item [0] is (3,32,32) tensor + int label
    - test_vit_loss_fn_imported_correctly: vit_loss_fn from example_vit_cifar is same as from flops_fit.examples.vit (same function or equivalent behavior)

    Import pattern at top of new test classes: use local imports inside each test method (same pattern as existing tests in file).

    NOTE: Do NOT modify any existing test classes or lines. Only append after the final line of the file.
  </action>
  <verify>
    # Count tests before and after
    python -m pytest tests/test_examples.py --collect-only -q 2>&1 | tail -5

    # Run all tests — must pass including new ViT tests
    python -m pytest tests/ -x -q 2>&1 | tail -5
  </verify>
  <done>New ViT test classes (TestViTContract, TestViTLossFunction, TestCIFAR10DatasetLazyLoad, TestViTExampleScript) in test_examples.py. Total test count exceeds 188 (12+ new tests). All tests pass including existing 188.</done>
</task>

</tasks>

<verification>
# Run the full test suite
python -m pytest tests/ -q 2>&1 | tail -5

# Verify the example script runs in mock mode
python -m flops_fit.examples.example_vit_cifar 2>&1 | head -20

# Verify key imports
python -c "
from flops_fit.examples import VisionTransformer, vit_loss_fn, CIFAR10Dataset
from flops_fit.examples.example_vit_cifar import make_vit_factory, run
import torch

# End-to-end contract check
factory = make_vit_factory(num_layers=2, num_heads=8)
m = factory(embed_dim=64)
assert m.num_params() > 0
logits = m(torch.randn(1, 3, 32, 32))
assert logits.shape == (1, 10)
loss = vit_loss_fn(logits, torch.tensor([3]))
assert loss.ndim == 0
print('Phase 8 verification PASSED')
"
</verification>

<success_criteria>
- example_vit_cifar.py runs in mock mode: python -m flops_fit.examples.example_vit_cifar completes without error
- example_vit_cifar.py accepts --real flag (documented; not tested automatically)
- test_examples.py has 4 new test classes with 12+ tests for ViT
- Total tests exceed 188; all pass
- VisionTransformer and vit_loss_fn importable from flops_fit.examples
- Phase 8 EX-02 requirement: ViT + CIFAR example using find_optimal() for image scaling laws
</success_criteria>

<output>
After completion, create `.planning/phases/08-vit-and-cifar-example/08-02-SUMMARY.md`
</output>
