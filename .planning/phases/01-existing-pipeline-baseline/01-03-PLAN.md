---
phase: 01-existing-pipeline-baseline
plan: 03
type: execute
wave: 2
depends_on: ["01-01", "01-02"]
files_modified:
  - tests/test_visualizer.py
  - tests/test_pipeline.py
  - tests/conftest.py
autonomous: true

must_haves:
  truths:
    - "ScalingVisualizer creates IsoFLOP curve PNG files on disk"
    - "ScalingVisualizer creates scaling law PNG plots on disk"
    - "ScalingVisualizer creates tokens-per-param PNG plots on disk"
    - "Full pipeline plan->train->analyze->visualize completes in mock mode"
    - "Visualizer uses 1-decimal bucket rounding (documented inconsistency with analyzer)"
    - "Hydra configs load correctly with overrides"
  artifacts:
    - path: "tests/test_visualizer.py"
      provides: "Visualizer tests for plot creation and data loading"
      contains: "TestScalingVisualizer"
    - path: "tests/test_pipeline.py"
      provides: "End-to-end pipeline integration test and Hydra config tests"
      contains: "test_full_pipeline_mock_mode"
  key_links:
    - from: "tests/test_pipeline.py"
      to: "src/flops_fit/planner.py"
      via: "SweepPlanner import"
      pattern: "SweepPlanner"
    - from: "tests/test_pipeline.py"
      to: "src/flops_fit/trainer.py"
      via: "TrainingRunner import"
      pattern: "TrainingRunner"
    - from: "tests/test_pipeline.py"
      to: "src/flops_fit/analyzer.py"
      via: "ScalingLawAnalyzer import"
      pattern: "ScalingLawAnalyzer"
    - from: "tests/test_pipeline.py"
      to: "src/flops_fit/visualizer.py"
      via: "ScalingVisualizer import"
      pattern: "ScalingVisualizer"
---

<objective>
Write tests for the visualizer module (plot file generation) and a full pipeline integration test (plan->train->analyze->visualize in mock mode), plus Hydra config composition smoke tests.

Purpose: Complete the test coverage for Phase 1 by testing the final pipeline stage and verifying all stages work together end-to-end. The Hydra config tests ensure YAML overrides and presets work correctly.
Output: new test_visualizer.py, new test_pipeline.py, updated conftest.py with analysis fixtures
</objective>

<execution_context>
@/home/viggie/.claude/get-shit-done/workflows/execute-plan.md
@/home/viggie/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/01-existing-pipeline-baseline/01-RESEARCH.md
@.planning/phases/01-existing-pipeline-baseline/01-01-SUMMARY.md
@src/flops_fit/visualizer.py
@src/flops_fit/conf/planner.yaml
@src/flops_fit/conf/trainer.yaml
@src/flops_fit/conf/analyzer.yaml
@src/flops_fit/conf/visualizer.yaml
@tests/conftest.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create visualizer tests and add analysis fixtures</name>
  <files>tests/test_visualizer.py, tests/conftest.py</files>
  <action>
First, update `tests/conftest.py` to add an analysis fixture:

1. `sample_analysis` fixture: Returns a dict matching the ScalingAnalysis.to_dict() schema. Include n_opt_fit, d_opt_fit, l_opt_fit dicts (each with name, coefficient_k, exponent_a, r_squared, k_ci=None, a_ci=None, formula), optimal_points list (3 entries), and optimal_ratio float. Use realistic values (e.g., k=0.01, a=0.5 for N_opt).

2. `analysis_json` fixture (depends on tmp_path, sample_analysis): Write sample_analysis to tmp_path/"analysis"/"scaling_laws.json" (creating the analysis subdirectory) and return the path.

Create `tests/test_visualizer.py`:

At the very top of the file, BEFORE any other imports:
```python
import matplotlib
matplotlib.use("Agg")
```

Then import matplotlib.pyplot as plt, ScalingVisualizer, pytest, etc.

Add `autouse` fixture for matplotlib cleanup:
```python
@pytest.fixture(autouse=True)
def cleanup_matplotlib():
    yield
    plt.close("all")
    plt.rcdefaults()
```

Class TestScalingVisualizer:

3. `test_plot_isoflops_creates_file(tmp_path, results_json, analysis_json)`: Create ScalingVisualizer with results_path=results_json, analysis_path=analysis_json, output_dir=tmp_path/"plots". Call plot_isoflops(save=True). Assert (tmp_path/"plots"/"isoflops_curves.png").exists(). Assert file size > 0.

4. `test_plot_scaling_laws_creates_file(tmp_path, results_json, analysis_json)`: Same setup. Call plot_scaling_laws(save=True). Assert scaling_laws.png exists with nonzero size.

5. `test_plot_tokens_per_param_creates_file(tmp_path, results_json, analysis_json)`: Same setup. Call plot_tokens_per_param(save=True). Assert tokens_per_param.png exists with nonzero size.

6. `test_plot_all_creates_three_files(tmp_path, results_json, analysis_json)`: Create visualizer. Call plot_all(save=True). Assert returns list of 3 figures. Assert all 3 PNG files exist.

7. `test_plot_isoflops_uses_1_decimal_buckets(tmp_path, results_json, analysis_json)`: Characterization test. This documents that the visualizer uses `np.round(np.log10(budget), 1)` for bucketing, which is different from analyzer's 2-decimal rounding. Create visualizer, call load_data(). Manually compute what the visualizer would do: `np.round(np.log10(df["compute_budget"]), 1)`. Verify the number of unique 1-decimal buckets. Add comment: "Characterization: visualizer uses 1-decimal bucket rounding vs analyzer's 2-decimal. Known inconsistency."

8. `test_load_data_filters_completed(tmp_path)`: Write results JSON with 2 completed and 1 failed experiment. Create visualizer. Call load_data(). Assert DataFrame has only 2 rows.

9. `test_load_data_loads_analysis(tmp_path, results_json, analysis_json)`: Create visualizer with both paths. Call load_data(). Assert analysis dict is not None and has "n_opt_fit" key.

10. `test_load_data_analysis_optional(tmp_path, results_json)`: Create visualizer with results_path=results_json but analysis_path pointing to nonexistent file. Call load_data(). Assert analysis is None (not an error).

11. `test_paper_style_sets_rcparams(tmp_path, results_json)`: Create visualizer with style="paper". Check that plt.rcParams["font.family"] == "serif" and plt.rcParams["savefig.dpi"] == 300. Note: _setup_style is called in __init__, so just check after construction.

12. `test_notebook_style_sets_rcparams(tmp_path, results_json)`: Create visualizer with style="notebook". Check that plt.rcParams["figure.figsize"] == [10, 7].
  </action>
  <verify>Run `cd /home/viggie/Projects/flops-fit && uv run pytest tests/test_visualizer.py -v` -- all tests pass.</verify>
  <done>test_visualizer.py has 10+ tests covering plot creation, data loading, style configuration, and bucket rounding characterization. conftest.py has analysis fixtures added. All pass.</done>
</task>

<task type="auto">
  <name>Task 2: Create pipeline integration test and Hydra config tests</name>
  <files>tests/test_pipeline.py</files>
  <action>
Create `tests/test_pipeline.py`:

At the very top:
```python
import matplotlib
matplotlib.use("Agg")
```

Import SweepPlanner, TrainingRunner, ScalingLawAnalyzer, ScalingVisualizer, numpy, matplotlib.pyplot, pytest, json.

Add matplotlib cleanup fixture (autouse, same as visualizer):
```python
@pytest.fixture(autouse=True)
def cleanup_matplotlib():
    yield
    plt.close("all")
    plt.rcdefaults()
```

Integration test:

1. `test_full_pipeline_mock_mode(tmp_path)`: End-to-end pipeline test.
   - Step 1 (Plan): Create SweepPlanner(min_flops=1e17, max_flops=1e19, num_compute_budgets=3, num_model_sizes=4). Call save_sweep(tmp_path/"sweep.json"). Assert configs returned and file exists.
   - Step 2 (Train): np.random.seed(42). Create TrainingRunner(mode="mock", sweep_path=tmp_path/"sweep.json", output_dir=tmp_path). Call run_sweep(resume=False). Assert all results have status="completed". Assert results.json exists.
   - Step 3 (Analyze): Create ScalingLawAnalyzer(results_path=tmp_path/"results.json", output_dir=tmp_path/"analysis"). Call analyze(). Assert n_opt_fit.r_squared > 0. Assert d_opt_fit.r_squared > 0. Assert l_opt_fit.r_squared > 0. Assert scaling_laws.json exists in analysis dir.
   - Step 4 (Visualize): Create ScalingVisualizer(results_path=tmp_path/"results.json", analysis_path=tmp_path/"analysis"/"scaling_laws.json", output_dir=tmp_path/"plots"). Call plot_all(save=True). Assert 3 figures returned. Assert all 3 PNG files exist (isoflops_curves.png, scaling_laws.png, tokens_per_param.png). Close all figures.

2. `test_pipeline_resume_from_partial(tmp_path)`: Run plan + train for all experiments. Delete results.json. Re-run plan (to get a fresh sweep). Run train for only the first half by interrupting (write partial results with first N experiments). Then run_sweep(resume=True). Assert all experiments are completed (resumed ones + new ones).

Actually, simplify test 2: just run the full plan->train, then run train again with resume=True. Assert the second run returns same number of results and doesn't re-train (check that the results file is not significantly different).

Hydra config tests:

3. `test_planner_config_loads()`: Use `hydra.initialize_config_module(config_module="flops_fit.conf", version_base=None)` as context manager. Inside, call `compose(config_name="planner")`. Assert cfg.compute.min_flops is a number > 0. Assert cfg.compute.num_budgets > 0. Assert cfg.output.sweep_path == "outputs/sweep.json".

4. `test_planner_config_overrides()`: Same initialization. Compose with overrides=["compute.min_flops=1e15", "compute.num_budgets=3"]. Assert cfg.compute.min_flops == 1e15. Assert cfg.compute.num_budgets == 3.

5. `test_trainer_config_loads()`: Compose config_name="trainer". Assert cfg.mode == "mock". Assert cfg.paths.sweep == "outputs/sweep.json". Assert cfg.resume == True.

6. `test_analyzer_config_loads()`: Compose config_name="analyzer". Assert cfg.paths.results == "outputs/results.json".

7. `test_visualizer_config_loads()`: Compose config_name="visualizer". Assert cfg.plots.style == "paper". Assert cfg.plots.show == False.

8. `test_all_configs_disable_hydra_output_dir()`: For each config (planner, trainer, analyzer, visualizer), compose and assert cfg.hydra.run.dir == "." and cfg.hydra.output_subdir is None. This characterizes the important behavior that Hydra doesn't change working directory.

Note: For Hydra tests, each test must use its own `with initialize_config_module(...)` context manager to avoid GlobalHydra state leaks. Import from `hydra import compose, initialize_config_module`.
  </action>
  <verify>Run `cd /home/viggie/Projects/flops-fit && uv run pytest tests/test_pipeline.py -v` -- all tests pass.</verify>
  <done>test_pipeline.py has 1 full pipeline integration test, 1 resume test, and 6 Hydra config tests. All pass.</done>
</task>

</tasks>

<verification>
Run the complete test suite:
```bash
cd /home/viggie/Projects/flops-fit && uv run pytest tests/ -v --tb=short
```
All tests across all files pass. No failures, no warnings about matplotlib backends or Hydra state leaks.

Final coverage check:
```bash
cd /home/viggie/Projects/flops-fit && uv run pytest tests/ --cov=flops_fit --cov-report=term-missing
```
Verify coverage exists for planner.py, trainer.py, analyzer.py, visualizer.py, model.py.
</verification>

<success_criteria>
- test_visualizer.py has 10+ tests covering all 3 plot types, data loading, style configs
- test_pipeline.py has full end-to-end integration test (plan->train->analyze->visualize)
- test_pipeline.py has Hydra config composition tests for all 4 CLI commands
- All tests pass: `uv run pytest tests/ -v` shows 0 failures
- Tests run in headless mode (Agg backend, no display needed)
- Known inconsistencies documented in characterization test comments
</success_criteria>

<output>
After completion, create `.planning/phases/01-existing-pipeline-baseline/01-03-SUMMARY.md`
</output>
