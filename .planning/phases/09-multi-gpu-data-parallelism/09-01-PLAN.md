---
phase: 09-multi-gpu-data-parallelism
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - pyproject.toml
  - src/flops_fit/trainer.py
  - tests/test_trainer.py
autonomous: true

must_haves:
  truths:
    - "_local_train() uses Accelerator for device placement and backward pass"
    - "Single-GPU execution (python script.py) produces the same results as before (no regression)"
    - "accelerate is listed as a dependency in pyproject.toml"
    - "unwrap_model() is used to access num_params() after prepare()"
    - "Only main process writes results.json in run_sweep_from_plan()"
  artifacts:
    - path: "src/flops_fit/trainer.py"
      provides: "Accelerate-integrated _local_train and run_sweep_from_plan"
      contains: "from accelerate import Accelerator"
    - path: "pyproject.toml"
      provides: "accelerate dependency declaration"
      contains: "accelerate>=1.0.0"
    - path: "tests/test_trainer.py"
      provides: "Tests verifying Accelerate integration in single-process mode"
      contains: "TestAccelerateIntegration"
  key_links:
    - from: "src/flops_fit/trainer.py"
      to: "accelerate"
      via: "Accelerator().prepare() and accelerator.backward()"
      pattern: "accelerator\\.prepare\\(|accelerator\\.backward\\("
    - from: "src/flops_fit/trainer.py"
      to: "accelerator.unwrap_model"
      via: "Custom method access on DDP-wrapped model"
      pattern: "unwrap_model.*num_params"
    - from: "src/flops_fit/trainer.py"
      to: "accelerator.is_main_process"
      via: "File I/O gating for results.json"
      pattern: "is_main_process"
---

<objective>
Integrate HuggingFace Accelerate into TrainingRunner for multi-GPU data parallelism.

Purpose: Enable users with multiple GPUs to run scaling law sweeps faster via data parallelism, without modifying their model class or dataset. Single-GPU behavior is preserved as the default.

Output: Modified trainer.py using Accelerate, updated pyproject.toml with dependency, new tests verifying the integration works in single-process mode.
</objective>

<execution_context>
@/home/viggie/.claude/get-shit-done/workflows/execute-plan.md
@/home/viggie/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/09-multi-gpu-data-parallelism/09-RESEARCH.md

@src/flops_fit/trainer.py
@src/flops_fit/api.py
@src/flops_fit/data.py
@tests/test_trainer.py
@pyproject.toml
</context>

<tasks>

<task type="auto">
  <name>Task 1: Integrate Accelerate into TrainingRunner</name>
  <files>pyproject.toml, src/flops_fit/trainer.py</files>
  <action>
1. Add `"accelerate>=1.0.0"` to the `dependencies` list in `pyproject.toml`.

2. Modify `_local_train()` in `src/flops_fit/trainer.py`:
   - Import `from accelerate import Accelerator` at the top of the file.
   - At the start of `_local_train()`, create `accelerator = Accelerator()`.
   - After creating model, dataloader, and optimizer, call `model, optimizer, dataloader = accelerator.prepare(model, optimizer, dataloader)`.
   - Remove the manual `device = _get_device()` call and `model.to(device)` line. Accelerate handles device placement via `prepare()`.
   - Remove the manual `inputs = inputs.to(device)` and `targets = targets.to(device)` lines. Accelerate's prepared dataloader places tensors on the correct device automatically.
   - Replace `loss.backward()` with `accelerator.backward(loss)`.
   - For `num_params()` access after prepare, use `unwrapped_model = accelerator.unwrap_model(model)` and call `unwrapped_model.num_params()` instead of `model.num_params()`.
   - For loss gathering across processes (for accurate multi-GPU loss reporting), gather loss with:
     ```python
     loss_val = accelerator.gather(loss.detach().unsqueeze(0)).mean().item()
     total_loss += loss_val
     ```
     instead of `total_loss += loss.item()`.
   - After the training loop, clean up with `accelerator.free_memory()` before `del model` and `torch.cuda.empty_cache()`.
   - Keep the `_get_device()` function (other code may use it), but `_local_train` no longer calls it.

3. Modify `run_sweep_from_plan()`:
   - Gate the incremental `results.json` write with a check. Since `_local_train` creates Accelerator internally (per experiment), the sweep loop itself runs identically on all processes. However, to be safe for future refactors, import Accelerator and use `accelerator.is_main_process` or check `int(os.environ.get("LOCAL_RANK", 0)) == 0` to gate file writes.
   - Simpler approach: since Accelerator is created inside `_local_train` and destroyed after, the sweep loop does NOT run inside a DDP context. All processes run the full sweep loop independently. The correct approach is: check `int(os.environ.get("RANK", "0")) == 0` before writing results.json to guard against the case where all processes reach the write. Import `os` at module level.
   - Similarly, gate the `tqdm` progress bar: only show it when `int(os.environ.get("RANK", "0")) == 0`.

4. Do NOT modify `api.py` -- Accelerate activation is controlled by the launch method (accelerate launch vs python), not by API parameters. This matches the research recommendation.

5. Do NOT auto-scale learning rate. Per research: for scaling law experiments, LR scaling is not needed.

Important: The Accelerator is created INSIDE `_local_train`, not at module level and not at sweep level. This is because each experiment has a different model architecture, and creating Accelerator per experiment avoids stale DDP gradient bucket state. The Accelerator constructor is lightweight (reads env vars, selects device). This pattern was validated in the research (Pitfall 7).
  </action>
  <verify>
Run `cd /home/viggie/Projects/flops-fit && python -c "from flops_fit.trainer import TrainingRunner; print('import ok')"` to verify import succeeds.

Run `cd /home/viggie/Projects/flops-fit && python -c "from accelerate import Accelerator; a = Accelerator(); print(f'device={a.device}, num_processes={a.num_processes}')"` to verify Accelerate is installed and works.

Run existing tests: `cd /home/viggie/Projects/flops-fit && python -m pytest tests/test_trainer.py -v` -- all existing tests must pass (no regression).
  </verify>
  <done>
_local_train() uses Accelerator for prepare/backward/unwrap_model. pyproject.toml includes accelerate>=1.0.0. All existing test_trainer.py tests pass unchanged.
  </done>
</task>

<task type="auto">
  <name>Task 2: Add Accelerate integration tests</name>
  <files>tests/test_trainer.py</files>
  <action>
Add a new test class `TestAccelerateIntegration` to `tests/test_trainer.py` with the following tests:

1. `test_local_train_uses_accelerator()`:
   - Patch `accelerate.Accelerator` to spy on its creation inside `_local_train`.
   - Use the existing `tiny_model_cls`, `tiny_dataset`, `tiny_experiment` fixtures.
   - Call `runner._local_train(...)` and verify that `Accelerator()` was called.
   - Alternatively (simpler): verify that `_local_train` works by checking its return values are valid (this is already tested, so focus on Accelerate-specific behavior).
   - Best approach: call `_local_train`, then verify the result is valid. The existing `test_local_train_returns_loss_flops_walltime` already covers this. Instead, write a test that specifically verifies the `unwrap_model` path works by checking that `actual_flops` still matches `6 * num_params * num_tokens` (proving `unwrap_model().num_params()` returned the correct value).

2. `test_local_train_no_manual_device_placement()`:
   - Verify that `_local_train` does NOT call `_get_device()` directly by checking the code path works on CPU without CUDA. This is implicitly tested but make it explicit: mock `torch.cuda.is_available` to return False, run `_local_train`, verify it completes successfully. (This proves Accelerate handles device placement, falling back to CPU.)

3. `test_sweep_results_json_written_once()`:
   - Create a SweepPlan with 2 experiments.
   - Run `run_sweep_from_plan()`.
   - Verify `results.json` exists and contains exactly 2 results.
   - Verify no duplicate experiment_ids (proving only one process wrote).

4. `test_accelerate_backward_compatibility()`:
   - Run `_local_train` with the tiny model/dataset.
   - Verify the returned `(loss, actual_flops, wall_time)` tuple has the same types and ranges as before the Accelerate integration.
   - loss: float, not NaN, > 0
   - actual_flops: float, > 0, equals 6 * N * D
   - wall_time: float, > 0

Reuse the existing fixtures (`tiny_model_cls`, `tiny_dataset`, `tiny_experiment`) from `TestLocalTraining`. Either move them to module-level fixtures or duplicate them in the new class.

Preferred: Move `tiny_model_cls`, `tiny_dataset`, `tiny_experiment` to module-level fixtures (outside any class) so both `TestLocalTraining` and `TestAccelerateIntegration` can use them. This avoids duplication.
  </action>
  <verify>
Run the full test suite: `cd /home/viggie/Projects/flops-fit && python -m pytest tests/ -v` -- all tests pass, including new Accelerate tests.

Check test count increased: should be 201 + new tests (expect ~205).
  </verify>
  <done>
New TestAccelerateIntegration class with 3-4 tests verifying: Accelerator is used (via unwrap_model proving correct num_params), no regression on return types/values, results.json written correctly. Full suite passes with 205+ tests.
  </done>
</task>

</tasks>

<verification>
1. `python -m pytest tests/ -v` -- all tests pass (201+ existing + new Accelerate tests)
2. `python -c "from flops_fit.trainer import TrainingRunner"` -- imports successfully
3. `python -c "from accelerate import Accelerator; print(Accelerator().device)"` -- Accelerate installed and functional
4. `grep -n "accelerator.prepare" src/flops_fit/trainer.py` -- confirms Accelerate integration in _local_train
5. `grep -n "accelerator.backward" src/flops_fit/trainer.py` -- confirms backward() uses Accelerate
6. `grep -n "unwrap_model" src/flops_fit/trainer.py` -- confirms model unwrapping for num_params
7. `grep -n "is_main_process\|RANK" src/flops_fit/trainer.py` -- confirms file I/O gating
8. `grep "accelerate" pyproject.toml` -- confirms dependency
</verification>

<success_criteria>
- Accelerate integrated into _local_train() with prepare/backward/unwrap_model pattern
- pyproject.toml lists accelerate>=1.0.0 as dependency
- All 201 existing tests pass (no regression)
- 3-4 new tests verify Accelerate-specific behavior
- run_sweep_from_plan gates file writes for multi-process safety
- No changes to api.py, data.py, sweep.py, or model_factory.py
</success_criteria>

<output>
After completion, create `.planning/phases/09-multi-gpu-data-parallelism/09-01-SUMMARY.md`
</output>
