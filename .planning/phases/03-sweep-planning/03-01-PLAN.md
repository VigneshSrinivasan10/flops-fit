---
phase: 03-sweep-planning
plan: 01
type: tdd
wave: 1
depends_on: []
files_modified:
  - src/flops_fit/sweep.py
  - tests/test_sweep.py
autonomous: true

must_haves:
  truths:
    - "plan_sweep() returns a SweepPlan with Experiment entries for each compute budget"
    - "SweepPlan.total_flops returns sum of compute budgets across all experiments"
    - "Experiments have size_param_value, num_params, num_tokens, and tokens_per_param"
    - "Invalid size_param values are skipped gracefully, not crashed on"
    - "Infeasible experiments (too few tokens) are filtered out"
  artifacts:
    - path: "src/flops_fit/sweep.py"
      provides: "Experiment dataclass, SweepPlan dataclass, plan_sweep() function"
      contains: "class Experiment"
    - path: "tests/test_sweep.py"
      provides: "Unit tests for sweep planning logic"
      contains: "test_plan_sweep"
  key_links:
    - from: "src/flops_fit/sweep.py"
      to: "src/flops_fit/model_factory.py"
      via: "create_model() for probing param counts"
      pattern: "from flops_fit.model_factory import create_model"
---

<objective>
Implement the sweep planning module (sweep.py) using TDD: Experiment and SweepPlan dataclasses, probe-based size-to-param mapping, IsoFLOP grid generation, and feasibility filtering.

Purpose: This is the core logic that translates user-provided compute budgets + model class into an inspectable experiment grid. It bridges the model factory (Phase 1) with the training engine (Phase 4).
Output: Working sweep.py with plan_sweep() function, fully tested.
</objective>

<execution_context>
@/home/viggie/.claude/get-shit-done/workflows/execute-plan.md
@/home/viggie/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-sweep-planning/03-RESEARCH.md
@src/flops_fit/model_factory.py
@src/flops_fit/planner.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: TDD sweep.py - dataclasses and plan_sweep()</name>
  <files>src/flops_fit/sweep.py, tests/test_sweep.py</files>
  <action>
RED phase: Create tests/test_sweep.py with a MockModel fixture (same pattern as test_api.py: `__init__(self, width=64, num_layers=4)`, `num_params()` returns `width * num_layers * 100`). Write failing tests for:

1. **Experiment dataclass**: Create an Experiment instance, verify all fields (experiment_id, compute_budget, size_param_value, num_params, num_tokens, tokens_per_param).

2. **SweepPlan dataclass**: Create a SweepPlan with a list of Experiments, verify `total_flops` property returns sum of all experiment compute_budgets, `num_experiments` returns count, `compute_budgets` stores original user budgets, `model_cls_name` stores class name, `size_param` stores param name.

3. **plan_sweep() basic**: Call `plan_sweep(model_cls=MockModel, size_param="width", model_kwargs={"num_layers": 4}, compute_budgets=[1e15, 1e16])`. Assert it returns a SweepPlan. Assert `len(plan.experiments) > 0`. Assert all experiments have `compute_budget` in the provided budgets list. Assert `num_tokens > 0` and `num_params > 0` for all experiments.

4. **plan_sweep() size probing**: Verify that experiments have different `size_param_value` values within a single compute budget (i.e., the grid varies model size). Verify `num_params` matches what MockModel would return for that `size_param_value`.

5. **plan_sweep() feasibility filtering**: Use a very small compute budget (e.g., 1e8) where large models would need < N/10 tokens. Verify those infeasible configs are filtered out (no experiment with tokens_per_param < 0.1).

6. **plan_sweep() skips invalid sizes**: Create a model class whose constructor raises ValueError for certain size values (e.g., width must be even). Pass it to plan_sweep. Verify it returns a plan (doesn't crash), just with fewer experiments (the invalid sizes are skipped).

7. **plan_sweep() optional params**: Verify `num_sizes_per_budget` kwarg controls how many model sizes per budget (default 7). Verify optional `min_size` and `max_size` kwargs constrain the probed size range. Verify optional `flops_per_param_per_token` kwarg (default 6) changes token calculation.

8. **SweepPlan repr**: Verify `repr(plan)` contains experiment count, budget count, and total_flops.

GREEN phase: Create src/flops_fit/sweep.py with:

- `Experiment` dataclass with fields: experiment_id (str), compute_budget (float), size_param_value (int), num_params (int), num_tokens (int), tokens_per_param (float).

- `SweepPlan` dataclass with fields: experiments (list[Experiment]), model_cls_name (str), size_param (str), compute_budgets (list[float]), model_kwargs (dict). Properties: total_flops (sum of experiment compute_budgets), num_experiments (len). Custom `__repr__`.

- `_probe_model_sizes(model_cls, size_param, model_kwargs, size_values) -> list[tuple[int, int]]`: For each size value, call `create_model()` from model_factory, call `num_params()`, collect (size_value, num_params). Wrap each probe in try/except to skip invalid sizes. Delete probe model after reading params. Sort result by num_params ascending.

- `_generate_size_values(min_size, max_size, num_values) -> list[int]`: Generate log-spaced integer size values from min to max. Round to multiples of 64 for GPU efficiency. Deduplicate after rounding.

- `plan_sweep(model_cls, size_param, model_kwargs=None, compute_budgets, *, num_sizes_per_budget=7, min_size=64, max_size=8192, flops_per_param_per_token=6) -> SweepPlan`:
  1. Generate size values via _generate_size_values
  2. Probe all sizes via _probe_model_sizes
  3. For each compute budget, select feasible probed sizes (filter where D = C / (flops_per_param_per_token * N) >= N/10)
  4. If more feasible sizes than num_sizes_per_budget, select evenly-spaced subset via numpy
  5. Create Experiment entries with tokens = C / (flops_per_param_per_token * N)
  6. Return SweepPlan

REFACTOR: Clean up, ensure all tests pass.

Key implementation details:
- Use `from flops_fit.model_factory import create_model` for probing (not direct instantiation)
- Use `del model` after probing to free memory
- Use `numpy.logspace` for log-spaced size values (consistent with existing planner.py)
- Feasibility filter: skip experiments where `num_tokens < num_params // 10` (matches existing planner.py logic)
- Within a single budget, deduplicate by size_param_value (can happen after rounding)
  </action>
  <verify>
Run `cd /home/viggie/Projects/flops-fit && python -m pytest tests/test_sweep.py -v`. All tests pass. Run `python -m pytest tests/ -v` to verify no regressions.
  </verify>
  <done>
sweep.py exists with Experiment, SweepPlan, and plan_sweep(). All test cases pass: basic grid generation, size probing accuracy, feasibility filtering, invalid size skipping, optional params, and repr formatting.
  </done>
</task>

</tasks>

<verification>
- `python -m pytest tests/test_sweep.py -v` -- all sweep tests pass
- `python -m pytest tests/ -v` -- no regressions in existing tests
- `python -c "from flops_fit.sweep import plan_sweep, SweepPlan, Experiment; print('imports ok')"` -- importable
</verification>

<success_criteria>
plan_sweep() returns a SweepPlan with correct Experiment entries, total_flops works, invalid sizes are handled gracefully, and infeasible experiments are filtered.
</success_criteria>

<output>
After completion, create `.planning/phases/03-sweep-planning/03-01-SUMMARY.md`
</output>
